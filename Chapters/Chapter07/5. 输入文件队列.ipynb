{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import time"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1. 生成文件存储样例数据。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 将int64转换成tf.train.Feature格式\n",
    "def _int64_feature(value):\n",
    "    return tf.train.Feature(int64_list=tf.train.Int64List(value=[value]))\n",
    "\n",
    "# 定义将数据写入多少个文件\n",
    "num_shards = 2 \n",
    "\n",
    "# 定义每个文件写入多少个样本\n",
    "instances_per_shard = 2 \n",
    "\n",
    "for i in range(num_shards):\n",
    "    filename = ('../../datasets/data.tfrecords-%.5d-of-%.5d' % (i, num_shards)) \n",
    "    \n",
    "    # 将Example结构写入TFRecord文件。\n",
    "    writer = tf.python_io.TFRecordWriter(filename)\n",
    "    \n",
    "    for j in range(instances_per_shard):\n",
    "        \n",
    "        # Example结构仅包含当前样例属于第几个文件以及是当前文件的第几个样本。\n",
    "        example = tf.train.Example(features=tf.train.Features(feature={\n",
    "            'i': _int64_feature(i),\n",
    "            'j': _int64_feature(j)}))\n",
    "        writer.write(example.SerializeToString())\n",
    "    writer.close()  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2. 读取文件。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[b'..\\\\..\\\\datasets\\\\data.tfrecords-00000-of-00002'\n",
      " b'..\\\\..\\\\datasets\\\\data.tfrecords-00001-of-00002']\n"
     ]
    }
   ],
   "source": [
    "# 使用tf.train.match_filenames_once函数获取一个符合正则表达式的所有文件\n",
    "files = tf.train.match_filenames_once(\"../../datasets/data.tfrecords-*\")\n",
    "\n",
    "# 使用tf.string_input_producer 产生文件名队列\n",
    "filename_queue = tf.train.string_input_producer(files, shuffle=False, num_epochs = 4) \n",
    "\n",
    "# 使用tf.TFRecordReader去读文件名队列\n",
    "reader = tf.TFRecordReader()\n",
    "_, serialized_example = reader.read(filename_queue)\n",
    "\n",
    "# 解析一个样例\n",
    "features = tf.parse_single_example(\n",
    "      serialized_example,\n",
    "      features={\n",
    "          'i': tf.FixedLenFeature([], tf.int64),\n",
    "          'j': tf.FixedLenFeature([], tf.int64),\n",
    "      })\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    sess.run([tf.global_variables_initializer(), tf.local_variables_initializer()])\n",
    "    print(sess.run(files))\n",
    "    \n",
    "    # 使用tf.train.Coordinator和tf.train.start_queue_runners管理和启动线程\n",
    "    coord = tf.train.Coordinator()\n",
    "#     threads = tf.train.start_queue_runners(sess=sess, coord=coord)\n",
    "    for i in range(6):\n",
    "        print(sess.run([features['i'], features['j']]))\n",
    "    \n",
    "    # 使用coord.request_stop停止所有线程\n",
    "    coord.request_stop()\n",
    "    coord.join(threads)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3. 组合训练数据（Batching）"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "Missing parentheses in call to 'print'. Did you mean print(cur_example_batch, cur_label_batch)? (<ipython-input-10-2c02f28334ff>, line 13)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;36m  File \u001b[1;32m\"<ipython-input-10-2c02f28334ff>\"\u001b[1;36m, line \u001b[1;32m13\u001b[0m\n\u001b[1;33m    print cur_example_batch, cur_label_batch\u001b[0m\n\u001b[1;37m                          ^\u001b[0m\n\u001b[1;31mSyntaxError\u001b[0m\u001b[1;31m:\u001b[0m Missing parentheses in call to 'print'. Did you mean print(cur_example_batch, cur_label_batch)?\n"
     ]
    }
   ],
   "source": [
    "example, label = features['i'], features['j']\n",
    "batch_size = 2\n",
    "capacity = 1000 + 3 * batch_size\n",
    "example_batch, label_batch = tf.train.batch([example, label], batch_size=batch_size, capacity=capacity)\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    tf.global_variables_initializer().run()\n",
    "    tf.local_variables_initializer().run()\n",
    "    coord = tf.train.Coordinator()\n",
    "    threads = tf.train.start_queue_runners(sess=sess, coord=coord)\n",
    "    for i in range(3):\n",
    "        cur_example_batch, cur_label_batch = sess.run([example_batch, label_batch])\n",
    "        print\n",
    "    coord.request_stop()\n",
    "    coord.join(threads)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tensorflow",
   "language": "python",
   "name": "tensorflow"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}

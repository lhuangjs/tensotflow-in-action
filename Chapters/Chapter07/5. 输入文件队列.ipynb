{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import time"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1. 生成文件存储样例数据。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 将int64转换成tf.train.Feature格式\n",
    "def _int64_feature(value):\n",
    "    return tf.train.Feature(int64_list=tf.train.Int64List(value=[value]))\n",
    "\n",
    "# 定义将数据写入多少个文件\n",
    "num_shards = 2 \n",
    "\n",
    "# 定义每个文件写入多少个样本\n",
    "instances_per_shard = 2 \n",
    "\n",
    "for i in range(num_shards):\n",
    "    filename = ('../../datasets/data.tfrecords-%.5d-of-%.5d' % (i, num_shards)) \n",
    "    \n",
    "    # 将Example结构写入TFRecord文件。\n",
    "    writer = tf.python_io.TFRecordWriter(filename)\n",
    "    \n",
    "    for j in range(instances_per_shard):\n",
    "        \n",
    "        # Example结构仅包含当前样例属于第几个文件以及是当前文件的第几个样本。\n",
    "        example = tf.train.Example(features=tf.train.Features(feature={\n",
    "            'i': _int64_feature(i),\n",
    "            'j': _int64_feature(j)}))\n",
    "        writer.write(example.SerializeToString())\n",
    "    writer.close()  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2. 读取文件。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[b'..\\\\..\\\\datasets\\\\data.tfrecords-00000-of-00002'\n",
      " b'..\\\\..\\\\datasets\\\\data.tfrecords-00001-of-00002']\n",
      "[0, 0]\n",
      "[0, 1]\n",
      "[1, 0]\n",
      "[1, 1]\n",
      "[0, 0]\n",
      "[0, 1]\n"
     ]
    }
   ],
   "source": [
    "# 使用tf.train.match_filenames_once函数获取一个符合正则表达式的所有文件\n",
    "files = tf.train.match_filenames_once(\"../../datasets/data.tfrecords-*\")\n",
    "\n",
    "# 使用tf.string_input_producer 产生文件名队列\n",
    "filename_queue = tf.train.string_input_producer(files, shuffle=False, num_epochs = None) \n",
    "\n",
    "# 使用tf.TFRecordReader去读文件名队列\n",
    "reader = tf.TFRecordReader()\n",
    "_, serialized_example = reader.read(filename_queue)\n",
    "\n",
    "# 解析一个样例\n",
    "features = tf.parse_single_example(\n",
    "      serialized_example,\n",
    "      features={\n",
    "          'i': tf.FixedLenFeature([], tf.int64),\n",
    "          'j': tf.FixedLenFeature([], tf.int64),\n",
    "      })\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    sess.run([tf.global_variables_initializer(), tf.local_variables_initializer()])\n",
    "    print(sess.run(files))\n",
    "    \n",
    "    # 使用tf.train.Coordinator和tf.train.start_queue_runners管理和启动线程\n",
    "    coord = tf.train.Coordinator()\n",
    "    threads = tf.train.start_queue_runners(sess=sess, coord=coord)\n",
    "    for i in range(6):\n",
    "        print(sess.run([features['i'], features['j']]))\n",
    "    # 使用coord.request_stop停止所有线程\n",
    "    coord.request_stop()\n",
    "    coord.join(threads)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3. 组合训练数据（Batching）"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1 0 0] [0 1 0]\n",
      "[0 0 1] [0 0 0]\n"
     ]
    }
   ],
   "source": [
    "example, label = features['i'], features['j']\n",
    "\n",
    "# 一个batch中包含的样例数目\n",
    "batch_size = 3\n",
    "\n",
    "# 组合样例的队列中最多可以存储的样例个数\n",
    "capacity = 1000 + 3 * batch_size\n",
    "\n",
    "# 使用tf.train.batch函数组合样例\n",
    "example_batch, label_batch = tf.train.batch([example, label], batch_size=batch_size, capacity=capacity)\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    tf.global_variables_initializer().run()\n",
    "    tf.local_variables_initializer().run()\n",
    "    \n",
    "    coord = tf.train.Coordinator()\n",
    "    threads = tf.train.start_queue_runners(sess=sess, coord=coord)\n",
    "        \n",
    "    for i in range(2):\n",
    "        cur_example_batch, cur_label_batch = sess.run([example_batch, label_batch])\n",
    "        print(cur_example_batch, cur_label_batch)\n",
    "        \n",
    "    coord.request_stop()\n",
    "    coord.join(threads)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "example: 0, lable: 0\n",
    "\n",
    "example: 0, lable: 1\n",
    "\n",
    "example: 1, lable: 0\n",
    "\n",
    "example: 1, lable: 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4. 使用tf.train.shuffle_batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1 1 0 0] [1 0 0 1]\n",
      "[1 1 0 0] [1 1 0 1]\n"
     ]
    }
   ],
   "source": [
    "# 使用tf.train.match_filenames_once函数获取一个符合正则表达式的所有文件\n",
    "files = tf.train.match_filenames_once(\"../../datasets/data.tfrecords-*\")\n",
    "\n",
    "# 使用tf.string_input_producer 产生文件名队列\n",
    "filename_queue = tf.train.string_input_producer(files, shuffle=False, num_epochs = None) \n",
    "\n",
    "# 使用tf.TFRecordReader去读文件名队列\n",
    "reader = tf.TFRecordReader()\n",
    "_, serialized_example = reader.read(filename_queue)\n",
    "\n",
    "# 解析一个样例\n",
    "features = tf.parse_single_example(\n",
    "      serialized_example,\n",
    "      features={\n",
    "          'i': tf.FixedLenFeature([], tf.int64),\n",
    "          'j': tf.FixedLenFeature([], tf.int64),\n",
    "      })\n",
    "\n",
    "###############################################组合batch#########################\n",
    "example, label = features['i'], features['j']\n",
    "\n",
    "# 一个batch中包含的样例数目\n",
    "batch_size = 4\n",
    "\n",
    "# 组合样例的队列中最多可以存储的样例个数\n",
    "capacity = 1000 + 3 * batch_size\n",
    "\n",
    "# 使用tf.train.shuffle_batch函数组合样例,min_after_dequeue参数限制了出队时队列中元素的最少个数\n",
    "example_batch, label_batch = tf.train.shuffle_batch([example, label], batch_size=batch_size, capacity=capacity, \n",
    "                                                   min_after_dequeue = 30)\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    tf.global_variables_initializer().run()\n",
    "    tf.local_variables_initializer().run()\n",
    "    \n",
    "    coord = tf.train.Coordinator()\n",
    "    threads = tf.train.start_queue_runners(sess=sess, coord=coord)\n",
    "    \n",
    "    for i in range(2):\n",
    "        cur_example_batch, cur_label_batch = sess.run([example_batch, label_batch])\n",
    "        print(cur_example_batch, cur_label_batch)\n",
    "        \n",
    "    coord.request_stop()\n",
    "    coord.join(threads)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "min_after_dequeue参数虽然限制了出队时队列中元素的最少个数，但是并不是队列中元素不足min_after_dequeuecan设置的值就不出队"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tensorflow",
   "language": "python",
   "name": "tensorflow"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
